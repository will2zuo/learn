#### 群聊消息存储方案
1. 群聊消息存多份，只存离线成员的消息，如果在实时给在线成员推消息失败的情况，会导致消息丢失
2. 群聊消息存多份，所有群友都存储，消息冗余多； 先落盘，等 ack 确认之后在进行删除，磁盘带宽占用大
3. 群聊消息存多份，只存未读ID的集合，未利用偏序；
4. 群聊消息存一份，只存最近最后一次的消息 id，last_ack_msgid。拉离线消息根据这个 id 往后拉就 ok

   group_members(gid, uid, last_ack_msgid);
   group_msgs(msgid,gid,sender_uid,time,content);

#### im 系统设计 1v1
##### 核心需求
  - 消息必达：消息不丢失、不重复、有序。
  - 低延迟：消息从发送到接收的延迟控制在毫秒级。
  - 高并发：支持百万级在线用户和每秒万级消息吞吐。
  - 多端同步：用户在不同设备上实时同步消息状态。
  - 安全性：消息加密、防篡改、用户身份认证。
  - 离线支持：用户离线时存储消息，上线后推送。
  - 扩展性：系统能水平扩展以应对用户增长。
##### 关键模块与实现
- 实时消息模块
  - 功能：消息发送、接收、推送。
  - 实现：
    - 长连接管理：使用 Netty、Go 的 Gorilla WebSocket 等框架管理连接。
    - 消息路由：
      - 用户在线时，通过连接服务直接推送消息。
      - 用户离线时，消息存入离线队列（Redis Sorted Set 或 Kafka）。
    - 消息 ID 生成：雪花算法（Snowflake）生成全局唯一 ID，保证消息有序。
    - ACK 机制：客户端收到消息后返回 ACK，服务端未收到则重试。
- 存储模块
  - 消息存储：
    - 在线消息：使用 Redis 缓存最近消息，加速读取。
    - 持久化存储：使用 MySQL（分库分表）或分布式数据库（Cassandra、TiDB）存储全量消息。
  - 用户与会话数据：
    - 用户关系：MySQL 存储好友列表、群组成员。
    - 会话列表：Redis 缓存用户最近会话，减少数据库查询。
- 可靠性设计
  - 消息必达
    - 重试机制：服务端未收到 ACK 时，按指数退避策略重试。
    - 消息持久化：消息发送时先写入数据库，再推送客户端。
    - 离线消息同步：用户上线后拉取未接收消息。
  - 消息去重
    - 过消息 ID 或唯一键（发送者 + 时间戳）去重。

#### im 系统设计 群聊
- 选择合适的扩散模式（写扩散 vs 读扩散），平衡存储与性能。
  - 读扩散：适用于大群消息，存储一条群消息，成员按需拉取；存储成本低；实时推送压力大，需频繁查询在线成员；
  - 写扩散：适用于小群，每个成员单独存储消息；存储成本高（消息数 × 成员数），大群场景不可行；推送高效，适合实时在线成员多的场景。
- 严格保证消息有序性，通过全局 ID 和服务端时序控制。
  - 使用分布式 ID 生成算法（如 Snowflake、Redis 原子操作）生成全局有序的群消息 ID。
  - 消息通过统一的消息队列（如 Kafka）按分区顺序处理，确保同一群的消息顺序一致
- 高效管理成员状态，结合缓存和消息队列快速扩散消息。
  - redis 存储成员状态
  - 管理进出成员
- 优化海量消息存储，分级存储 + 冷热分离降低成本。
  - 消息分级存储：
    - 热数据：最近 7 天的消息存入 Redis 或内存数据库（如 Dragonfly）。
    - 冷数据：历史消息归档到 MySQL 分库分表或对象存储（如 S3）。 
  - 消息索引优化：
    - 为群 ID、消息时间戳、发送者等字段建立联合索引，加速查询
- 完善监控与容错，确保消息必达和系统高可用。


##### 消息推送性能优化策略
  - 分片推送：将大群成员列表分片（如每 100 人一组），并行推送消息。
  - 消息合并：将多条消息合并为批量请求，减少网络开销（如 10 条消息合并为 1 次推送）。
  - 边缘计算：在多地部署边缘节点，就近推送消息，降低跨国延迟。
  - 异步处理：使用消息队列（如 Kafka）异步处理消息扩散和存储，避免阻塞主线程。

##### 可靠性设计
- 消息重试：
  若未收到客户端 ACK，按指数退避策略重试（如 1s、3s、5s）。 
- 去重机制：
  客户端和服务端通过消息 ID 去重，避免重复消费。 
- 最终一致性：
  允许短暂的消息状态不一致（如“已发送”但未“已读”），通过定期同步修复。

##### 大群场景的特殊处理
- 读扩散 + 分级存储：
    - 仅存储一份群消息，成员拉取时按时间范围分页查询。
    - 使用 Elasticsearch 加速消息检索。
- 限流与降级：
对万人以上大群启用消息频率限制（如 10 条/秒），超出后排队或丢弃低优先级消息。
- 消息分区：
按群 ID 或 Hash 值将消息分布到不同 Kafka 分区，分散处理压力。

##### 典型问题与解决方案
1. 消息乱序
- 根因：网络延迟或并行推送导致客户端接收顺序不一致。
- 方案： 
  - 服务端按消息 ID 严格排序后推送。
  - 客户端缓存消息，按 ID 顺序渲染。
2. 热点群消息洪峰
- 根因：万人群突发大量消息，导致服务端过载。 
- 方案： 
  - 消息队列分区 + 限流（如 Kafka 分区按群 ID 散列）。
  - 客户端消息合并发送（如 200ms 合并一次）。
3. 成员列表频繁变更 
- 根因：群成员进出频繁，遍历列表时可能漏推消息。 
- 方案： 
  - 使用版本号或快照机制：推送消息时记录当前群成员版本，变更时触发版本更新。
  - 最终一致性：允许短暂延迟，通过离线消息补偿。

#### having 和 where 的区别
having 从分组的结果中再次筛选，where 过滤的是行

#### mysql 中删除数据之后，磁盘的占用仍然很大
1. 删除数据之后，磁盘并没有立即释放出来，而是被标记为空闲状态，为了提高性能，避免频繁的磁盘分配和回收操作
   解决办法：用 optimize table 来释放碎片化的磁盘空间；但是这个操作会锁表，造成短暂的不可用

#### 网关设计：
需要做的事情：
1. 协议转换 rpc 转 http 或者 http 转 rpc
2. 统一鉴权、统一监控、服务熔断、降级、流量控制、路由转发、服务发现、异步调用、链路调用

#### mq作用：解耦、异步处理、削峰填谷
#### mq 面临的问题：
- 重复消费的问题；
    - 费幂等性：
        - 保证幂等性：在 mq 数据持久化设置一个全局的唯一 msgid，还有 redis 的 set

- 靠性传输问题/保证消息不丢失
  - 发送端 ： 重试机制，保证消息投递成功，收到 mq server 的 ack 确认就认为消息投递成功
  - server: 数据持久化，集群模式 kafka 的 topic 有 n 个 partition ，每个 partition 在不同机器上还有副本
  - 消费端：手动 ack 确认或者 offset

- 使用事务的方式，阻塞的等待成功或者失败，会导致吞吐量减少
  - confirm 确认，异步不会造成阻塞
  - 持久化成功之后在进行 confirm 回调通知
  - 消费者主动 ack或 offset 确认

- 如何保证消息的顺序性
  - 通过指定 key 的方式落在同一个 partition 中，同一个 partition 保证是有序的
    或者 在同一个 queue 中

- 怎么快速处理积压的消息
  - 快速修复 consumer，保证能正常消息
  - 增加机器来加快消费，或者是新建一个更大的 queue 来存储未消费的消息，等空闲时间慢慢消费
  - 如果是过期消息被丢弃了，只能重新写个脚本来重新查询被丢弃的消息重新进行消费
  - 如果长期处理不了，只能采用丢弃+批量重导的方式，在闲暇时间再来查询修复

- 如何设计一个 mq
  - 支持伸缩扩容机制，
  - 支持数据持久化，避免消息丢失
  - 高可用，leader -> 多副本->borber
  - 支持数据 0 丢失


#### 限流：
- 计数限流: 在固定时间内限制固定的请求数量，但是存在在重置节点突发【节点前后请求最大请求数量】请求超过限制
- 令牌桶限流：桶的大小固定，令牌生成的速度固定，消耗令牌的速度不固定，每次请求都会从桶里取令牌，如果没有令牌就丢弃这次请求，能动态调整令牌发放的速度，针对突发流量
- 漏桶限流：桶的大小固定，消费的速度固定

#### mysql 大数据量处理
1. 分区
2. 分表分库
3. 读写分离
4. 数据库集群
5. 冷热数据归档
6. 优化查询 sql 语句

#### 分表分库存在的问题
1. 迁移和扩容的问题；
   解决：使用在线迁移工具，如阿里云的DTS和腾讯云的CDM
2. 跨库查询性能的问题；跨库 join 问题
   尽量避免跨库查询；或者是讲关联的操作提前到应用层；或者是用一些中间件、mycat 来优化关联查询
3. 数据一致性问题；
   分布式事务或者redis 分布式锁来解决
4. 跨库分布式事务的问题；
   - 可以使用两段提交 （2pc）或者三段提交来解决 （3pc），或者一些支持分布式事务的中间件，如阿里巴巴的 TDDL 或者当当网的 Sharding-JDBC
   - 两段提交：准备 - 提交，在第二阶段提交时奔溃可能导致数据不一致
   - 三段提交：准备 - 预提交 - 最终提交
5. 自增 id 重复，插入性能下降
   1. 分布式 id 生成器【雪花算法】来生成唯一 id，这些算法通常使用时间戳、机器 ID 和序列号的组合来确保 ID 的全局唯一性，同时保持高性能
   2. uuid，UUID 是全局唯一的，但长度较长（通常为 36 个字符），可能会影响性能和存储空间
   3. id 段分配，可能导致 id 浪费
   4. 双主键，一个字段是自增 id，一个是分片的 id

#### 分表分库的类型以及方案
- 水平分表分库: 按照数据行以 range 或者 hash 或者去模的方式分，表相同但是数据不同，库相同但是表不同 user_0 user_1
- 垂直分表分库: 按照字段来分，分库是按照模块来分，order。user

#### mysql 分区是什么
- 分区是指将大表分成小表，但是物理上仍然是一个表，分布在不同的磁盘上，但是查询数据还是向普通表一样
- 作用：提高查询性能，减少 io 操作，同时也方便管理数据


#### http1 和 http2 的区别
1. 连接复用，提高了传输的效率
2. 二进制传输，http1是文本传输，更快的解析速度和更小的数据包大小，减少了传输时间和延迟
3. 头部压缩，htt1 每次传输都是要重复发送头部信息，http2压缩头部信息，减少了传数量，加快了传输速度
4. 流优先级，http2 允许为每个流设置优先级，使得重要资源有限传输
5. 流量控制

#### put 和 patch 的区别：
1. put 是幂等的，patch 不一定是幂等的；
2. put 是替换整个资源，patch 是替换部分资源

#### 如何实现一个死锁
两个事务，一个是先更新 id=1，再更新 id=2 的；另一个事务是先更新 id=2 的，再去更新 id=1；

#### 如何处理高并发

- 使用缓存
- 优化数据库，提高数据使用效率
- 负载均衡
- 静态页面
- 分布式部署，业务分离
- 防盗链
- 限制大文件下载
- cdn 加速

#### 怎么解决商品超卖和秒杀的问题

- 加锁
- 队列

#### API 安全接口解决方案

- 非对称加密 rsa

  利用公钥和密钥，公钥传递数据，密钥解密获取数据

- Md5 加密

- 令牌 access_token

#### web 安全

- XSS 攻击，跨站脚本攻击：往 web 页面插入可以执行的脚本代码，达到盗取用户信息或者侵犯用户隐私的目的
    - 攻击方式
        - 非持久型：诱骗点击 url 链接
        - 持久型：一般是表单提交
    - 防范
        - web 渲染的页面必须是来自服务端，做转义
        - 不要相信前端传递过来的数据，将所有字段转义后处理
- CSRF 跨站伪造请求攻击
    - 攻击方式
        - 被攻击者登录了网站并保留了 cookie 信息
        - 访问了危险网站，并受引诱登录了之前的网站
        - 被攻击者没有做 csrf 防范
    - 防范
        - 正确的使用 get、post请求和cookie
        - 在非 get 中使用 token加密
        - 渲染表单加上 csrfToken，后端验证
- SQL 注入：没有有效的过滤用户的输入，使攻击者向服务端提交了恶意的 sql 查询代码，导致原 sql 查询逻辑改变
    - 防范
        - 数据库最小操作权限
        - 内容必须转义
        - 尽量不要使用拼接 sql 语句
        - 不要将 sql 错误暴露给用户
- DDOS 攻击，分布式拒绝服务，使用大量的请求资源导致资源过载，服务不可用
    - 防范
        - 网络上做好架构，负载均衡
        - 限制单个 ip 的访问次数
        - 关闭不必要的服务
        - 防火墙
        - 堆机器
- dns 和 http 劫持
    - dns：被篡改访问的地址
    - http：被篡改被访问的内容

### 如何保证接口的幂等性
确保同一个请求无论被执行多少次，其结果都是一致的，不会导致重复操作或数据不一致
- 保证唯一约束
- 悲观锁和乐观锁
- 分布式锁
- 缓存
- token 机制

### http 的连接池怎么实现的
HTTP连接池的实现主要基于连接复用的理念，通过维护一组预先建立的连接，减少频繁建立和关闭连接的开销，从而提高性能和资源利用率

### go 中的 http 连接池是怎么实现的
net/http 包通过 Transport 组件实现了 HTTP 连接池的功能

### 服务注册和服务发现是什么流程
用于动态管理服务实例的上下线以及服务之间的调用
#### 服务注册
服务注册是指服务提供者在启动时，将自己的元数据（如服务名、IP地址、端口等）注册到服务注册中心。注册中心会记录这些信息，并定期通过心跳机制检查服务的健康状态。如果服务实例下线或不可用，注册中心会将其从服务列表中移除
#### 服务发现
服务发现是指服务消费者在需要调用其他服务时，向注册中心查询目标服务的地址信息。注册中心会返回可用的服务实例列表，消费者可以根据这些信息进行服务调用
### 如果设置了分布式锁，redis 主节点挂了，会有什么后果
- 锁信息丢失，如果主节点挂掉之前还未同步锁信息给从节点，可能导致多个客户端获取相同的锁，引发并发冲突和数据不一致
- 并发安全问题
#### 解决方案
- Redlock算法，在大多数节点中获取成功获取锁，才是真正的加锁成功
- ZooKeeper 分布式锁
- RedissonMultiLock
### redis 是如何保证原子性的
- 单线程模式，每个命令是顺序执行的
- redis 的原子性操作
- 事务机制，通过 MULTI 和 EXEC 命令将多个命令打包成一个事务
- WATCH 命令：Redis 的 WATCH 命令允许客户端监控一个或多个键。如果在事务执行前这些键被其他客户端修改，事务将被取消，从而保证事务的原子性
- Lua 脚本：Redis 支持使用 Lua 脚本执行一系列命令，Lua 脚本在执行过程中是原子的，Redis 会将脚本作为一个整体进行执行
- 持久化机制：Redis 提供了 RDB 快照和 AOF 日志两种持久化方式，确保在发生故障时数据能够恢复到一致状态，进一步保证数据的原子性

### 进程/线程/协程有什么区别
- 进程：操作系统资源分配的基本单位，每个进程拥有独立的虚拟内存空间、文件描述符等资源
- 线程：进程内的执行单元，共享同一进程的资源（内存、文件句柄等），但拥有独立的栈和寄存器。
- 协程：用户级轻量级线程，由程序自身控制调度（非抢占式），不依赖操作系统内核。

### 接口变慢了应该如何排查？导致接口变慢的原因有哪些？
- 定位，明确是什么原因造成
  - 是单个接口变慢，还是整体变慢
  - 是某个时间段变慢还是特定的请求变慢
  - 用监控工具观察QPS、响应时间、错误率变化
- 分层排查
  - 网络层 → 系统资源层 → 中间件层 → 应用代码层 → 数据库层 → 第三方服务层
- 网络原因
  - 带宽不足
  - TCP连接数达到上限
  - 网络丢包延迟高
  - DNS 解析变慢
- 系统资源问题
  - cpu 使用过高（频繁 gc）
  - 内存不足（oom 风险）
  - 磁盘 I/O 瓶颈
- 数据库问题
  - 慢查询
    - EXPLAIN 排查
  - 锁竞争
  - 连接池耗尽
  - 主从延迟
- 应用代码问题
  - 低效的算法
  - 内存泄露
  - 线程池分配不合理
  - 同步阻塞
- 中间件问题
  - redis大 key、热 key
    - 通过本地缓存+随机过期时间分散请求
  - kafka 消息堆积
  - Nginx 负载不均衡
  - 缓存击穿、雪崩
- 第三方服务依赖的问题
  - 外部 api 的超时
  - 服务熔断未恢复
- 预防措施
  - 定期压力测试
  - 自动扩容机制
  - 监控告警
  - 熔断降级
  - 防御性编程