[Go](https://github.com/will2zuo/learn/blob/main/go/index.md)

## GMP 模型
#### G：goroutine => 需要绑定 P 才能运行，在 G 的视角中，P就是 CPU

#### P：承上启下的调度器
1. 承上启下，实现 G 和 M 的动态有机结合
2. 对于 g 来说，只有被 p 调用才能运行
3. 对于 m 来说，是 m 的执行代理
4. p 的数量决定了g 的并发数量，可以用过 runtime.GOMAXPROCS 来设定

调度器的策略
1. work stealing机制 : 当本线程无可运行的g 时，尝试从其他线程绑定的 p 偷取g，而不是销毁线程
2. hand off 机制 : 当本线程因为g 进行系统调用阻塞时，就释放绑定的 p，把 p 转移给其他空闲的线程执行

#### M：machine，go 中对线程的抽象 => m 不直接执行 g，由 p 代理执行

#### GMP 模型调度的过程
![gmp.png](gmp.png)
1. 全局队列：存放的是等待运行的 g
2. p 的本地队列：和全局队列一样，存放的是等待运行的 g，存的数量有限，不超过 256 个。新建 g 时，g 优先加入p 的本地队列，如果队列满了，泽辉把本地队列中的一半的 g 移动到全局队列
3. p 列表：所有的 p 都在程序启动时创建，并保存到数组中，最多有 gomaxprocs（可配置） 个
4. m：线程相运行任务就得先获取 p，从 p 的本地队列获取 g，p 队列为空，m 也会尝试从全局队列拿一批 g 放到 p 的本地队列，或者从其他 p 偷取一半放到自己 p 的本地队列。m 运行 g，g 执行之后，m 会从 p 获取下一个 g，不断重复

#### go func 的调度流程
![img.png](img.png)

#### 调度器的生命周期
![img_1.png](img_1.png)

## Go 的垃圾回收机制
### 垃圾回收分类
1. 追踪式：从根对象出发，根据对象之间的引用关系，一步步推进知道扫描整个堆并确定要保留的对象，从而进行垃圾回收
2. 引用计数式：每个对象包含一个引用计数器，当引用计数器归零的时候就会被回收

### 根对象是什么
又叫做根集合，在垃圾回收过程中最先检查的对象：
1. 全局变量
2. 执行栈
3. 寄存器

### 三色标记法
1. 从所有根对象开始遍历，可达的先标记为灰色
2. 遍历所有灰色，变为黑色，再将可达的白色变为灰色
3. 重复第二步，直到遍历完所有对象，剩下的黑色则是可以存活的对象，白色的则是需要回收的对象

三色标记法也会存在 stw，gc 效率过低的问题，解决方法 => 写屏障、混合写屏障

如果不使用 stw ，会存在合法的对象也被 gc 给回收掉了

### 屏障机制
当以下两个条件同时满足时会破坏垃圾回收器的正确性：
1. 一个白色对象被黑色对象引用(白色被挂在黑色下)
2. 灰色对象与它之间的可达关系的白色对象遭到破坏(灰色同时丢了该白色)

为了保证gc 回收时，对象不被丢失：
1. 强三色不变式：既不存在黑色的对象引用白色的对象
2. 弱三色不变式：既所有黑色引用到的白色对象，都有可达的路径，这个白色对象必须存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象

#### 插入屏障
满足强三色不变式：既A 对象引用对象 B，B会被标记为灰色

#### 删除屏障
满足弱三色不变式：既被删除的对象，如果自身为灰色或者白色，那么标记为灰色

#### 混合写屏障
满足变式的弱三色不变式，结合了插入屏障和删除屏障的有点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。

流程：
1. gc 开始将栈上的所有对象标记为黑色，之后不会重复扫描，不需要stw
2. gc 期间，任何在栈上创建的对象，均为黑色
3. 被删除的对象标记为灰色【删除屏障】
4. 被添加的对象标记为回味【插入屏障】

混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高

## 触发 GC 的时机是什么时候
1. 手动触发： runtime.GC
2. 被动触发：使用系统监控，当一定时间【默认时间两分钟】没有 gc 时，强制触发；通过监控内存增长的比列来触发；如果没有开启 gc，则启动 gc
## Go Map 的实现
底层用的哈希查找表，并用链表法来解决哈希冲突

基本数据结构

```go
type hmap struct {
    count     int // map中键值对的数量
    B         uint8 // 桶的数量，即哈希表中桶的个数
    noverflow uint16 // 溢出桶的数量
    hash0     uint32 // 哈希种子,它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入
    buckets   unsafe.Pointer // 桶数组的指针
    oldbuckets unsafe.Pointer // 旧桶数组的指针，用于扩容时的数据迁移
    nevacuate uintptr // 扩容时的标记位
    extra *mapextra // 附加信息，包括溢出桶和哈希表的状态等
}

type mapextra struct {
	overflow    *[]*bmap
	oldoverflow *[]*bmap
	nextOverflow *bmap
}

// 在编译期间会转化
type bmap struct {
    tophash [bucketCnt]uint8 // 存储哈希值的高8位
    keys    [bucketCnt]key   // 存储键的数组
    values  [bucketCnt]value // 存储值的数组
    overflow *bmap           // 溢出桶的指针
}
```
![img_2.png](img_2.png)
哈希表 runtime.hmap 的桶是 runtime.bmap。每一个 runtime.bmap 都能存储 8 个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用 extra.nextOverflow 中桶存储溢出的数据。

桶的结构体 runtime.bmap 在 Go 语言源代码中的定义只包含一个简单的 tophash 字段，tophash 存储了键的哈希的高 8 位，通过比较不同键的哈希的高 8 位可以减少访问键值对次数以提高性能

随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容

### map 初始化
#### 字面量
一般是通过 key：value 的方式
```go
hash := map[string]int{
	"1": 2,
	"3": 4,
	"5": 6,
}
```
当哈希表中的元素数量少于或者等于 25 个时，会将所有的键值对一次加入到哈希表中，当哈希表中元素的数量超过了 25 个，编译器会创建两个数组分别存储键和值，这些键值对会通过如下所示的 for 循环加入哈希

### map 的增删改查
- 增：根据hash算法查到对应的桶，如果桶没有存满，就顺序在后面存，如果存满了，则存入溢出桶，通过链表链接
- 查：根据hash算法找到对应的桶，再经过高8位找到对应的值返回，如果没有，就去溢出桶找，没有直接返回
- 删：delete
### map 中的 key 为什么是无序的
因为在遍历map 时，不是固定的从 0 的 bucket 开始遍历的，而是随机序号的 bucket 开始遍历的
### map 扩容
#### 什么时候扩容
- 装载因子大于 6.5 = 元素个数/桶的个数
- 存在太多的溢出桶
    - 等量扩容
    - 其实内存整理，清理过多的溢出桶
    - 怎么判断溢出桶太多
        - 桶 b 的个数小于 15
            - 溢出桶数量超过 2^B
        - 桶 b 的个数大于 15
            - 溢出桶的数量超过 2^15

#### map 扩容是动态扩容
- 在调用写操作的时候增量扩容
- 从 oldbucket 迁移到bucket 中

### hash 算法
#### 开放寻址法
依次探测和对比目标键值是否在哈希表中
- 存在：会将值写在下一个索引为空的位置
- 不存在：就直接写到当前位置
#### 拉链法
通过 hash 算法找到一个桶
- 如果找到键相同的键值对，直接更新键值对
- 没有找到相同的键，直接在后面更新键值对，如果当前桶满了，就更新到溢出桶中
- 用的是链表做为底层的数据结构
## Go channel
### 数据结构
```go
type hchan struct {
  //channel分为无缓冲和有缓冲两种。
  //对于有缓冲的channel存储数据，借助的是如下循环数组的结构
	qcount   uint           // 循环数组中的元素数量
	dataqsiz uint           // 循环数组的长度
	buf      unsafe.Pointer // 指向底层循环数组的指针
	elemsize uint16 //能够收发元素的大小
  

	closed   uint32   //channel是否关闭的标志
	elemtype *_type //channel中的元素类型
  
  //有缓冲channel内的缓冲数组会被作为一个“环型”来使用。
  //当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置
	sendx    uint   // 下一次发送数据的下标位置
	recvx    uint   // 下一次读取数据的下标位置
  
  //当循环数组中没有数据时，收到了接收请求，那么接收数据的变量地址将会写入读等待队列
  //当循环数组中数据已满时，收到了发送请求，那么发送数据的变量地址将写入写等待队列
	recvq    waitq  // 读等待队列
	sendq    waitq  // 写等待队列


	lock mutex //互斥锁，保证读写channel时不存在并发竞争问题
}
```
![img_3.png](img_3.png)

- 用来保存goroutine之间传递数据的循环链表。=====> buf。
- 用来记录此循环链表当前发送或接收数据的下标值。=====> sendx和recvx。
- 用于保存向该chan发送和从改chan接收数据的goroutine的队列。=====> sendq 和 recvq
- 保证channel写入和读取数据时线程安全的锁。 =====> lock

channel 出现 panic 场景：
- 向已经关闭的 channel 写数据
- 关闭已经关闭的 channel
- 关闭为 nil 的 channel

chan 出现阻塞的场景：
- 给 nil 的chan 发送数据
- 读取 nil 的 chan

## slice 的扩容机制
go.1.18 版本之前：原 slice 的容量小于 1024 的扩容 2 倍，大于 1024 的扩容 1.25 倍

新版本的 go，原容量小于 256 的，扩容 2倍，大于 256 的扩容 newcap = oldcap+(oldcap+3*256)/4

## go 中 make 和 new 的区别
都是用来分配内存的内建函数
- new： 分配空间后是将内存清零，并没有初始化内存；new 可以为每种类型分配内存；返回的是指向内存的指针
- make：分配空间之后，是初始化内存，不是清零；make 只用于 slice、map、chan 三种；make 返回的是类型；

## map 删除一个 key，它的内存会被释放吗？
不会，只会做一个标记 EmptyOne，如果 map == nil 的时候，才会被 gc 回收

## go context 的作用
- 上下文控制
- go goroutine 之间的数据交换
- 超时控制

## 什么情况下 go 内存会泄露
- goroutine泄露，一般是没有被关闭或者没有添加超时控制，让 goroutine 一直阻塞，不能被 gc 回收

[Http](https://github.com/will2zuo/learn/blob/main/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/index.md)

## URL 访问网页的流程
1. 解析 URL
2. 查询 DNS 地址
3. 建立 tcp 连接
4. 发送 http 请求
5. 服务器处理 http 请求
6. 返回 http 响应
7. 浏览器页面渲染
8. tcp 断开连接

## TCP 三次握手、四次挥手
### 三次握手
![img.png](img.png)

### 四次挥手
![img_1.png](img_1.png)

[K8s](https://github.com/will2zuo/learn/blob/main/k8s/index.md)

## 容器是什么
容器的本质就是进程，根据 linux 的 namespace、cgrops、rootfs隔离出来

namespace： 隔离

cgroups： 限制资源

rootfs： 根文件系统

### 容器的分层 - 7层
- 最上层：读写层，可以提交到 docker hub 上被他们修改使用，删除的文件会被写入 whiteout 中，来屏蔽这个被删除的文件
- init 层：主要是修改 /etc/hosts 等数据，不会被 commit
- 最低下五层：只读层，rootfs 根文件系统，一般也是操作系统的文件目录

### 卷【volume】的挂载
在 rootfs 准备好之后，chroot 之前，将宿主机的目录挂载到容器中，在执行这个挂载操作，容器已经创建了，所以在宿主机上不可见，在容器内可见这个挂载事件

### 容器主要组成
- rootfs，就是容器的镜像，是容器的静态视图
- namespace+cgroups，容器运行时，是容器的动态视图

## k8s 设计与架构
- master：包含 api-server，controller-manager（控制器管理器），scheduler（调度器）
- etcd：持久化 k8s 整个集群数据
- node：kubelet（主要负责与容器运行时交互，调用网络插件和存储插件为容器配置网络和数据持久化）

k8s 的本质是 平台的平台，帮助用户构建上层平台的基础平台

## k8s 编排原理
### pod
#### 什么是 pod
是一组共享了某些资源的容器
- 共享同一个网络
- 共享同一个数据卷
- 可以同时运行一个或者多个容器，这些容器共享网络、存储等资源

#### pod 的资源共享需要启用一个中间容器
- infra 容器，永远第一个被启动，永远处于暂停状态
- 占用资源少
- 一个特殊的镜像

[MySql](https://github.com/will2zuo/learn/blob/main/mysql/index.md)

## 查询一条语句的流程
![img.png](img.png)
### 第一步：连接器
连接的过程要经过三次握手，因为是通过 tcp 连接的，也分为长连接【可以减少建立连接和断开的过程，也会使占用内存增多】和短连接
- 与客户端进行三次握手 tcp 连接
- 校验客户端的用户和密码
- 用户和密码正确，获取用户的权限在后面权限逻辑判断使用
#### 空闲的连接会被一直占用吗
不会，有过期时间，默认为 8 小时，通过 wait_timeout 定义。当过期之后，客户端再次请求才会返回错误
#### mysql 的连接有数量限制吗
有，默认为 151 个
#### 怎么解决长连接占用内存的问题？
- 定期断开长连接
- 客户端主动重置连接，5.7 版本之后 mysql_reset_connection()，调用可以重置连接，不需要重新鉴权，只是将连接恢复刚刚创建完的状态
### 第二步：查询缓存
8.0 之后移除了缓存；如果是查询语句，会先去缓存查，如果缓存中就直接返回，没有就继续执行，然后将查询结果缓存起来，key 是查询语句，value 是查询结果
### 第三步：解析语句
在查询之前，会被 sql 语句进行解析
#### 解析器
- 词法分析，分析出关键词和非关键词
- 语法分析，根据词法分析的结果，再根据语法规则，分析是否是满足 mysql 的语法，构建sql 语法树

表不存在或者字段不存在，是不会在解析器里判断的，在执行阶段中的预处理器中判断
### 第四步：执行语句
分为三个阶段：预处理阶段、优化阶段、执行阶段
#### 预处理器
- 检查表或者字段是是否存在
- 将 select * 中的 * 解析为表中的字段
#### 优化器
优化器主要负责将sql 查询语句的执行方案确定下来，可以用 explain 来查询执行计划
#### 执行器
执行sql 语句，从存储引擎获取记录返回给客户端

## Mysql 的一行数据是怎么存储的
### mysql 数据存放在哪个文件
- xx.idb: 表数据存放
- xx.frm： 表结构存放
- db.opt: 用来存储当前数据库的默认字符集和字符校验规则
### 表空间文件的结构是怎么样的
表空间由段（segment）、区（extent）、页（page）、行（row）组成
![img_1.png](img_1.png)
- 行【row】：数据库表中的数据都是按行存放的，每行根据不同行格式，有不同的存储结构
- 页【page】：数据库的读取和写入都是按页为单位，一页 16kb。页包含数据页、undo 日志页、溢出页等
- 区【extent】：Innodb 是使用 b+树来组织数据的，每一层都是用双向链表来连接，导致页与页之间的物理位置可能相隔很远，所以查询磁盘的时候有大量的随机 I/O，所以在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。
- 段【segment】：表空间是由多个段组成，段是有多个区组成。段分为数据段、索引段、回滚段等
    - 数据段：存放 B+树叶子节点的区的集合
    - 索引段：存放B+树的非叶子节点的区的集合
    - 回滚段：存放的是回滚数据的集合
#### InnoDB 行格式有哪些？
InnoDB 提供了 4 种行格式，分别是Redundant、Compact、Dynamic和 Compressed 行格式。

- compact：一种紧凑的行格式，设计的初衷是为了让一个数据页中存放更多的数据
- Dynamic和Compressed：两个都是紧凑的行格式，和 compact 很像

#### COMPACT 行格式长什么样？
![img_2.png](img_2.png)
##### 记录的额外信息
- 变长字段长度列表：保存的是变长字段的真实数据占用的字节数【varchar】，是按 【逆序存放】，主要是因为「记录头信息」中指向下一个记录的指针，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率。
- null 值列表：存储的是列数据中的 null 值，采用二进制的数据进行逆序排序
- 记录头信息
    - delete_mask：标识此条数据是否被删除
    - next_record：下一条记录的位置
    - record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录
##### 记录的真实数据
- row_id：隐藏 id，如果没有主键或者唯一约束，innodb 就会添加 row_id,不是必须，占用 6 字节
- trx_id：事务 id，记录数据由哪个事务生成，【必需】，占用6字节
- roll_pointer：记录上个版本的指针，【必需】，占用 7 字节，用于 mvcc 版本恢复

#### 行溢出之后，mysql 是怎么处理的
- compact 行格式，会用 20字节存储溢出页的地址，包含一部分真实数据+20字节的溢出页地址
- Compressed 和 Dynamic，采用完全行溢出的方式，只存储 20字节来记录溢出页的地址，不会存储真实数据
## 索引
### 什么是索引
索引是帮助存储引擎快速获取数据的一种数据结构，也就是数据的目录
### 索引的分类
- 按数据结构：b+索引、hash 索引、full-text 索引
    - ![img_3.png](img_3.png)
- 按物理存储：聚簇索引、二级索引
- 按字段特性：主键索引、唯一索引、普通索引、前缀索引
- 按字段个数：单列索引、联合索引
    - 联合索引【由多个字段组成】，使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配，前面我也用了四个例子说明了。

### explain 中字段解释
- possible_keys：可能用到的索引
- key：表示实际用到的索引，如果为 null 则是没有用索引
- key_len: 索引的长度
- rows: 表示扫描的行数
- type：表示用到的扫描的方式【效率从低到高】
    - ALl：全变扫描
    - index：全索引扫描
    - range：范围扫描
    - ref：非唯一索引扫描
    - eq_ref：唯一索引扫描
    - const：结果只有一条的主键或唯一索引扫描
### 什么时候需要索引
- 字段有唯一性的
- 经常要用在 where 后面的
- 经常用于 order by 或者 group by的，这样查询的时候就不用再次去排序
### 什么时候不需要索引
- where、order by、group by后面用不到的字段不需要索引，索引还会占用物理空间
- 字段中存在大量重复的数据或者分布比较均匀的数据【男女】
- 数据量较少的情况
- 经常更新的字段
### 什么时候索引会失效
- 使用模糊匹配，like %xx 或者 like %xx% 的时候
- 当查询条件中对索引进行了 计算、函数、类型转换操作
- 联合索引中没有使用最左匹配原则
- 在 where 子句中，or 前的列使用了索引，or 后面的列没有使用索引
### 优化索引的方法
- 前缀索引优化，将字符串的前几个字段创建索引，更快的查询速度和更少的存储空间
- 覆盖索引优化，增加联合索引，能直接查询出想要的数据，不需要回表操作，减少 I/O 操作
- 主键自增，每次插入新数据，叶子节点都是追加操作，不用重新移动数据
- 索引最好设置为 not null，索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化；NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题
### 索引的优缺点
优点：
- 加快查询的速度
- 加快连表的速度
- 在使用分组和排序，减少分组和排序的时间
- 减少服务器对数据的扫描
- 将随机 I/O 变成顺序 I/O

缺点：
- 需要占用物理空间，数据量越大，占用空间越多
- 创建和维护索引要消耗时间，随着数据量越大耗时越多
- 会降低表增删改的效率，因为每次增删改索引，b+树了为维护有序性，会进行动态维护


### 聚簇索引和二级索引
二级索引：存储的数据是主键 id，如果查询所有列的数据，需要做回表操作【就是先查询到主键 id，再通过主键 id 查询到相要的数据】，如果查询的数据在二级索引就能直接查到【比如主键 id】就不用做回表操作，这个叫做索引覆盖

主键索引：采用的是 b+tree 的数据格式，比二叉树的优势在于，查询效率更高，因为 b+树的最高就为 3-4层，只需要较少的 I/O
### 索引的数据结构
#### 二分查找树
二叉查找树的特点是一个节点的左子树的所有节点都小于这个节点，右子树的所有节点都大于这个节点， 但是当每次插入的元素都是二叉查找树中最大的元素，二叉查找树就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)，且不支持范围查找
#### 自平衡二叉树【AVL 树】
作用：为了解决二叉查找树会在极端情况下退化成链表的问题

主要是在二叉查找树的基础上增加了一些条件约束：每个节点的左子树和右子树的高度差不能超过 1，缺陷还是每个节点只有两个字节点，随着数据增多，高度增加，增加 I/O 查询次数
#### B 树
也叫多叉树，每个节点可以有 m 个字节点【m>2】,每个节点都包含【索引+数据】，所以会更多的 I/O 操作次数来读到有用的数据，对于查询某个节点的数据，非此节点的数据也会加载到内存中，增多磁盘 I/O 操作次数，也占用内存资源
#### B+树
在 B 树的基础上升级，只在叶子节点上存放数据和索引，非叶子节点存放索引

与 b 树的差异：
- 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引
- 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表
- 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）
- 非叶子节点中有多少个子节点，就有多少个索引

- B+树的叶子节点之间用双向链表连接，即可以向做遍历，又可以向右遍历
- B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB

#### MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构
- B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少
- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化
- B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。
### count(1)和 count(*)有什么区别，哪个效率更好
count 是 mysql 中 server 层中的聚合函数，查询的是不为 null 的记录，查询到一行就 +1，

count(1)=count(*) > count(主键)> count(字段)

如果表里存在二级索引，优化器就会选择二级索引进行扫描。尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计

Innodb和 MyISAM 对于 count 的区别
- MyISAM 有专门的字段 row_count 来记录行数
- Innodb 因为支持事务，没有专门的字段维护，只能遍历扫描

如何优化：
- 取近似值
- 专门维护一张表来统计
## 事务
### 什么是事务
### 事务包含的原则
- A【原子性】：一个事务中，要么全部完成，要么全部不完成，通过 undo log【回滚日志】
- C【一致性】：事务前后，数据满足完整性的约束，数据库保持一致性；一致性则是通过持久性+原子性+隔离性来保证；
- I【隔离性】：正在执行的事务对于其他事务是完全隔离的，不会相互影响，通过 mvcc【版本控制】或者锁机制来保证
- D【持久性】：事务提交之后，数据的修改是永久的，通过 redo log【重做日志】 来保证
### 并发事务导致的问题
在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题。

- 脏读
    - 一个事务读取到了另一个未提交事务修改的数据【因为这个未提交的事务可能发生回滚，修改的数据就变成了过期的数据】
- 不可重复读
    - 一个事务中多次读取同一个数据，但是前后读到的数据不一致 或者是读到了另一个事务提交的 update 数据
- 幻读
    - 一个事务中读到了其他事务中 insert 的数据或者是多次查询的数据数量不一致

![img_4.png](img_4.png)
SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低
### 事务的隔离级别
- 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；
- 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；
- 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；
- 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

![img_5.png](img_5.png)

针对不同的隔离级别，并发事务时可能发生的现象也会不同。
![img_6.png](img_6.png)

对于幻读，不建议升级为 串行化的隔离级别，因为会导致数据库的并发效率很差，解决方案：
- 针对快照对【select 查询】，通过 mvcc 版本控制方式解决幻读，因为默认的隔离级别，在事务执行看到的数据和事务开始看到的数据一致
- 针对当前读【select for update】，通过 next-key lock（记录锁+间隙锁）方式解决了幻读，如果其他事务在 next-key lock 范围内插入一条数据，会被阻塞，无法插入

对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同：
- 「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。
- 「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。

这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列」的比对，来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。

在可重复读隔离级别中，普通的 select 语句就是基于 MVCC 实现的快照读，也就是不会加锁的。而 select .. for update 语句就不是快照读了，而是当前读了，也就是每次读都是拿到最新版本的数据，但是它会对读到的记录加上 next-key lock 锁
### mvcc 版本控制
## 锁
### 有哪些锁
#### 全局锁
```sql
flush tables with read lock
# 释放锁
unlock tables
```
整个数据库就处于只读状态了，这时其他线程执行 对数据的增删改操作、对表结构的更改操作都会被阻塞

主要用作为全局备份，缺陷：如果数据量过大，耗时较长，会导致当前数据库只能只读，阻碍正常业务
#### 表级锁
- 表锁
- 元数据锁
- 意向锁
- AUTO-INC 锁；

##### 表锁
```sql
#表级别的共享锁,也就是读锁
lock tables t_student read;

#表级别的独占锁,也就是写锁
lock tables t_stuent write;
    
# 释放锁
unlock tables
```

对整个表加锁，会影响当前线程或其他线程对当前表的操作，造成阻塞

#### 元数据锁【MDL】
元数据锁一般不显示的调用，在对数据库操作时会自动加上 MDL 锁
- 在对一张表 curd 时，加 MDL 读锁
- 在对表结构变更时，加 MDL 写锁，写锁的优先级大于读锁

MDL 在事务提交之后才会被释放，所以如果存在长事务，可能导致线程阻塞
#### 意向锁
意向锁的目的是为了快速判断表里是否有记录被加锁。
#### 行级锁
- Record Lock：记录锁，也就是仅仅把一条记录锁上
- Gap Lock： 间隙锁，锁定一个范围，但是不包含记录本身；只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。
- Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。
- 插入意向锁：一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁），如果有就会被阻塞，直到拥有间隙锁的那个事务提交为止

#### update 更新没加索引的列会锁全表？
因为 innodb 的默认隔离级别为可重复读，在update 会加上next-key 锁来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录，从而避免了幻读现象，直到事务提交才会释放，如果没有索引，就会扫描全表，除了 select 可以操作，其他的操作都会被阻塞

如何避免：
- sql_safe_updates = 1 开启安全更新
    - 使用 where，where 后面的列表必须有索引
    - 使用 limit
    - 同时使用 where 和 limit，where 后的列可以不加索引
- 在测试阶段 explain 看是走的全表扫描还是索引
### 死锁
两个锁都在等对方释放资源，没有一个主动释放资源

必要的四个条件：
- 互斥
- 占有且等待
- 不可强占有
- 循环等待

如何避免：破坏四个必要条件中的一个
- 设置事务等待锁的超时时间 ； innodb_lock_wait_timeout = 10s
- 开启主动死锁检测 ；innodb_deadlock_detect = on

### 什么是悲观锁
每次去拿数据都会认为别人会修改数据，所以每次都拿数据都会上锁，适合多写的操作
### 什么时乐观锁
每次去拿数据都会认为别人不会修改数据，但是在更新数据的时候会判断在此期间有没有更新这个数据，适合多读的场景
## 日志
- undo log 回滚日志： 是 innodb 引擎生成的日志，实现事务的原子性。用作事务回滚和 mvcc 版本控制
    - ![img_7.png](img_7.png)
    - 作用：
        - 实现事务回滚，保障事务的原子性
        - 实现 MVCC（多版本并发控制）关键因素之一，MVCC 是通过 ReadView【快照】 + undo log 实现的
    - 在进行 修改、删除、新增操作，事务提交之前，会记录更新前的数据到 undo log 日志中，当事务回滚时，用 undo log 日志进行回滚
- redo log 重做日志：是 innodb 引擎层生成的日志，实现了事务中的持久化，用作数据恢复
- binlog 归档日志：server 层生成的日志，主要用于数据备份和主从复制

### Buffer Pool 缓冲池，提高数据库的读写性能
![img_8.png](img_8.png)
- 读数据时，如果buffer pool 存在，就直接返回，如果没有存在就去磁盘读取
- 写数据时，如果 buffer pool 存在，就直接在缓存更新，然后标记为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘的 I/O，脏页的数据不会立即刷新到磁盘，是由后台系统选择合适的时机刷新到磁盘

#### buffer pool 缓存什么
在 mysql 启动的时候，innodb 会为 buffer pool 申请一批连续的内存空间，按照默认 16kb 的大小分成一个个页，buffer pool 中的页就叫做缓存页

包含
- 数据页
- 索引页
- undo 页
    - 开启事务后，innodb 更新前，都会记录相应的 undo log，如果是更新操作，需要将更新前的旧值记录到 undo log，也会写入到 buffer pool 的 undo 页，主要是用来做回滚操作
- 插入缓存项
- 自适应哈希索引
- 锁信息

#### 为什么需要 redo log
因为更新操作，会先将更新的数据写入到内存 buffer pool，此时并没有刷新到磁盘上，但是更新已经完成，如果这个时候断电或者机器故障，就会导致更新的数据丢失。

正常的流程是：更新完成之后，innodb 会在适当的时候，把 buffer pool 的脏页数据刷新到磁盘上，这个就是 wal 技术。WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上，将随机写变成了顺序写

结论：
- 实现事务持久化的能力，让数据库有崩溃恢复的能力
- 将随机写变成了顺序写，提高了数据写入的性能

#### 什么是 redo log
是一个物理日志，记录了数据页更新了什么内容

#### redo log 和 undo log 的区别
- redo log 记录的是事务提交后，更新完成之后的数据
- undo log 记录的是事务开始前，更新之前的数据

事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务
![img_9.png](img_9.png)

#### 产生的 redo log 是直接写入磁盘的吗？
不是的，redo log 的日志也会写入自己的缓存 redo log buffer，后续在持久化到磁盘，因为每次 redo log 都写入磁盘，I/O 开销大

#### redo log 什么时候刷盘？
- mysql 正常关闭的时候
- 当 redo log buffer 记录的写入量大于 redo log buffer 内存一半时
- innodb 后台线程 每隔 1s 就像 redo log buffer 写入磁盘
- 每次事务提交就将 redo log buffer 写入磁盘，由参数 innodb_flush_log_at_trx_commit 控制，默认值是 1
    - 参数为 0 时，表示每次事务提交，将 redo log 写入在 redo log buffer，不会写入磁盘
    - 参数为 1 时，表示每次事务提交就将缓存到 redo log buffer 中的日志写入磁盘中，持久化
    - 参数为 2 时，表示每次事务提交，会将 redo log buffer 的日志写入 redo log 文件中，并不是写入到磁盘，是写入到了操作系统的文件缓存中
      ![img_10.png](img_10.png)

#### innodb_flush_log_at_trx_commit 为 0 和 2 的时候，什么时候才将 redo log 写入磁盘？
innodb 每隔 1s：
- 参数为 0，会通过 write()先写入操作系统的 page cache，然后在 fsync() 写入磁盘，如果数据库崩溃，会丢失 1s 的数据
- 参数为 2，通过 fsync() 写入磁盘，如果操作系统崩溃，才会丢失 1s 的数据

![img_11.png](img_11.png)

#### redo log 写满了怎么办
innodb 一个重做文件组【redo log group】，由 ib_logfile0 和 ib_logfile1 组成，通过循环写的方式写入日志，如果redo log 中的数据已经刷入磁盘，那么就会被删除。如果 redo log 文件满了，就不会再往里写数据，造成数据库阻塞，这个时候会停下来将脏页的数据刷新到磁盘中，腾出空间，主要由两个参数控制，一个记录写的位置 write pos，一个记录需要擦除的位置 checkpoint

### 为什么需要 binlog 日志
mysql 在完成一条更新操作之后，会生成一条 binlog 日志，事务提交之后会将 binlog 日志记录到 binlog 文件中，binlog 记录的是所有数据库表结构变更和表数据修改的日志，不会记录查询操作

#### redo log 和 binlog 的区别
- redo log 是在 innodb 引擎层实现的，binlog 是在 server 层实现，所有引擎都可以用
- redo log 是物理日志，记录的是在某个数据页做了什么更新操作，binlog 记录的是所有数据库表结构和数据的更新操作
- binlog 是追加写入，redo log 是循环写入
- binlog 的主要作用是用作备份数据和主从复制，redo log 是用于崩溃恢复
#### 主从数据库流程
![img_12.png](img_12.png)
- 写入 binlog 日志：主库记录 binlog 日志，更新本地数据
- 复制 binlog 日志：主库把 binlog 日志复制到每个从库上，从库保存在中继日志中
- 回放 binlog 日志：回放 binlog 日志，并更新引擎中的数据

主库事务提交之后，将操作写入 binlog 日志中，从库起一个 I/O 线程连接主库的 log dump 线程，将 binlog 日志复制到从库的 repay log 日志中，再起一个线程将中继日志中的数据更新到存储引擎中，实现主从数据一致性

##### MySQL 主从复制还有哪些模型？
- 同步复制：主库提交事务要等所有从库响应复制成功，才会返回客户端
- 异步复制（默认模型）：binlog 日志异步复制给从库，但是这种一旦主库出问题就会导致数据丢失
- 半同步复制：MySQL 5.7 版本之后，不用等所有从库返回复制成功，只要一部分复制成功响应回来就行

#### binlog 什么时候刷入磁盘
事务提交的时候会先将 binlog 写入到 binlog cache 日志中，然后在写入 binlog 文件，这个时候并没有写入磁盘，最后是通过系统写入磁盘，这个时候通过一个参数 sync_binlog 来控制写入时机

- 参数为 0时：每次提交事务只 write()，不 fsync()，由操作系统择机写入磁盘
- 参数为 1时：每次提交都会 write，然后马上同步到磁盘
- 参数为 n 时：每次事务提交都会 write，但是要积累到 n 个才写入磁盘
## 分表分库的流程
- 水平分表分库
    - 按数据的范围进行区分
- 垂直分表分库
    - 按字段的类型进行区分

## 数据库的三大范式
- 保证每一列都是不可再分的属性
- 保证每一列都依赖主键
- 保证每一列都和主键有直接的关系，而不是间接关系

[Redis](https://github.com/will2zuo/learn/blob/main/redis/index.md)

## 基本数据结构
- string
- hash
- list
- set 集合
- zset 有序集合

### 应用场景
- String： 缓存对象、常规计数、分布式锁、共享 session
- List： 消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等
- Hash： 缓存对象、购物车等。
- Set: 聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等
- Zset: 排序场景，比如排行榜、电话和姓名排序等。
- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；【数据可能有偏差】
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。

### 常见的数据类型是怎么实现的
![img_1.png](img_1.png)

## Redis 的单线程为什么那么快？
- 在内存中运行
- I/O 多路复用机制
## 宕机了，数据怎么快速恢复：redis 的持久化
### AOF

先执行redis 命令，在将命令写入到日志中，这样的好处就是不会阻碍当前的写操作，
但是潜在风险：1.如果执行完命令就宕机了，这个命令和相应的数据就会丢失；2.虽然不会阻碍当前的写操作，但是会给下一个操作带来阻碍的风险

### AOF 的三种回写操作：作用就是减少数据丢失的风险
1. alawys： 同步写回，每个写命令执行完，就同步的将日志写回磁盘
2. everysec：每秒写回，每次命令执行完，就先写入内存缓冲区，每隔一秒把缓冲区的日志写回磁盘
3. no：由操作系统控制写回，每个写命令执行完，先把日志写入 aof 文件的内存缓冲区，由操作系统来决定什么时候将缓冲区写入磁盘

### AOF 日志过大，会触发什么机制？AOF 的重写机制

作用：解决 AOF 文件过大带来的问题
1. 文件系统的限制，无法保存较大的文件
2. 如果文件过大，会给写入日志带来较大的性能挑战，性能低
3. 宕机恢复，AOF 文件过大，会导致数据恢复慢，执行效率低

AOF 重写的主要思想：就是将多条写入命令，最后合并成一条命令执行

AOF 重写会阻塞吗？不会
1. 是由子进程  bgrewriteaof 来完成的
2. 一个拷贝，两处日志：一个拷贝时指每次重写时，主线程会 fork 一个子线程，把内存拷贝一份给子线程，这里就包含最新的数据，子线程可以在不影响主线程的情况下操作；两处日志: 正在使用的 aof 日志；新的 aof 重写日志
3. 总结来说，每次 aof 重写时，redis 都会先执行一个内存拷贝，用于重写，然后两个日志在重写的过程中，新写入的数据不会丢失

在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」。
![img_2.png](img_2.png)
### RDB
将某一时刻的内存数据，以二进制的方式写入磁盘；数据的恢复效率比 AOF 高
#### RDB 会阻塞主线程吗？
由两个生成 RDB 文件的命令来决定的：save 和 bgsave
1. 使用 save，就会在主线程生成 RDB 文件，如果生成 RDB 文件的时间过长，就会阻碍主线程
2. bgsave，会创建一个子进程来生成 RDB 文件，这样可以避免阻塞主线程
## 数据同步，主从数据库怎么实现数据一致
主从复制
### 第一次同步
1. 第一阶段是建立链接、协商同步
2. 第二阶段是主服务器同步数据给从服务器；
3. 第三阶段是主服务器发送新写操作命令给从服务器。
   ![img_4.png](img_4.png)

主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。
### 分摊主服务器的压力
主从复制的耗时主要在 生成 RDB 文件和传输 RDB 文件，如果 redis的多个从服务器都从主服务器全量同步，就会阻塞主服务器线程，无法提供服务，也会给占用主服务器的网络带宽，对主服务器响应命令产生影响

解决办法：让从服务器来同步数据，主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器。
![img_5.png](img_5.png)
### 增量复制
主从服务器在完成第一次同步后，就会基于长连接进行命令传播，如果出现了网络问题断开连接，就可以用增量复制的方式进行同步
![img_6.png](img_6.png)
### 如何判断从哪里开始复制？
repl_backlog_buffer：【环形】缓冲区，在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令
## 主库挂了，如何不间断服务：哨兵机制
哨兵机制的作用：主从节点故障转移
### 哨兵的主要工作
哨兵节点主要负责三件事情：监控、选主、通知。
### 如何判断主节点故障
哨兵会每隔一秒 ping 主节点，如果主节点在规定的时间内没有响应，就会被判定为主观下线，
这个时候哨兵就会给其他哨兵发起命令来判断主节点是否是客观下线，由哨兵们根据自身的网络状态投票，如果票数达到了【配置文件中的 quorum 配置项】，就会被判断为客观下线，这个时候就会发起故障转移
### 由哪个哨兵来进行主从故障转移
当主节点被判定为客观下线，最先发现的哨兵就会发起投票，来做这次故障转移的 leader，如果票数大于等于哨兵配置文件中的 quorum 值或者拿到半数以上的赞成票就会成为 leader 进行故障转移
### 主从故障转移的过程是怎样的？
- 选出一个从节点将其转换为主节点【从节点如何选择】
    - 过滤掉已经离线和网络不好的从节点
    - 将剩下的节点进行三轮考察，顺序从优先级、复制进度、ID 号筛选，一轮胜利就会作为主节点
- 将已下线的旧主节点的从节点，改为复制新主节点
- 将新主节点的服务器信息，通过 发布者/订阅者机制 发送给客户端
- 继续监视旧主节点，等它重新上线，将其设置为新主节点的从节点

## Redis 的过期删除和内存淘汰
### 过期策略有哪些?
- 定时删除
- 惰性删除
- 定期删除

#### 定时删除的策略是怎样的
在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。

优点：
- 可以保证过期的 key 能尽快的被删除，快速的释放内存，对内存最为友好

缺点：
- 过期 key 过多的情况下，会占用 cpu 时间，在 cpu 紧张的情况下，会影响服务器的响应时间和吞吐量

#### 惰性删除策略
不主动删除过去 key，每次访问时检查是否过期，如果过期了就删除 key

优点：
- 因为每次访问再去检查是否过期，对资源占用少，对 cpu 友好

缺点：
- 如果过期的 key 长期没有被删除，会占用内存空间

#### 定期删除策略
每隔一段时间，从数据库中随机抽取一批 key进行检查，如果过期了就删除

优点：
- 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。

缺点：
- 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。
- 难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

#### redis 的删除策略是什么
Redis 选择「惰性删除+定期删除」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。
### 内存淘汰策略有哪些？
#### 不进行内存淘汰【noeviction】
redis 3.0 之后的默认策略，当内存满了，会给客户端报错，不然其继续写入
#### 在设置了过期时间的数据中进行淘汰
##### volatile-random
淘汰设置了过期时间的任意键值
##### volatile-ttl
优先淘汰更早过期的键值
##### volatile-lru
Redis3.0 之前，默认的内存淘汰策略）淘汰所有设置了过期时间中最久未使用的键值
##### volatile-lfu
Redis 4.0 后新增的内存淘汰策略）淘汰所有设置了过期时间中最少使用的键值
#### 在所有数据中淘汰
##### allkeys-random
随机淘汰任意键值;
##### allkeys-lru
淘汰整个键值中最久未使用的键值；
##### allkeys-lfu
Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

## 如何避免缓存雪崩、缓存击穿、缓存穿透？
### 雪崩
大量 redis 同一时间过期或者 redis 宕机，大流量都直接请求到数据库
![img_7.png](img_7.png)
#### 解决办法：针对不同诱因，策略也有所不同
#### 大量数据同时过期
- 均匀的设置过期时间：保证在同一时间没有大量的缓存同时失效
- 互斥锁：只允许一个请求来构建缓存，最好加个超时时间，不然遇到阻塞会影响到整个业务
- 后台更新缓存：定时更新或者缓存被淘汰时通知后台业务更新缓存
#### redis 宕机
- 服务熔断或请求限流机制：暂停对业务的访问，直接返回错误，减少对数据库的压力
- 构建高可用的集群

### 缓存击穿
![img_8.png](img_8.png)
缓存的热点数据突然失效，导致流量直接打到数据库
#### 解决办法
- 不给缓存设置过期时间，由业务来更新缓存
- 互斥锁方案
### 缓存穿透
用户访问的数据，既不在缓存中，也不在数据库中
![img_9.png](img_9.png)
#### 解决办法
- 限制非法请求
- 缓存空值或者零值
- 使用布隆过滤器，快速判断数据是否存在

## 数据如何和缓存保持一致
### 延迟双删：先删除缓存，更新数据库，在删除缓存

### 先更新数据库，在删除缓存
如果出现第二部操作失败，也会导致数据不一致

解决办法：
- 重试机制：利用消息队列来进行重试，如果失败就再次消费
- 订阅 mysql 的 binlog 日志，通过 binlog 日志拿到具体要操作的数据，然后再执行删除缓存操作

### 为什么是删除缓存不是更新缓存
删除一个数据，相比更新一个数据更加轻量级，出问题的概率更小。而且在业务中，有的缓存是多张表聚合而成，操作会非常耗时。从另外一个角度，不是所有的缓存数据都是频繁访问的，更新后的缓存可能会长时间不被访问，所以说，从计算资源和整体性能的考虑，更新的时候删除缓存，等到下次查询命中再填充缓存，是一个更好的方案