## kafka 什么
分布式的消息引擎 或者 消息队列 - 消息中间件 也是分布式流处理平台

## kafka 的消息传输协议是怎样的
- 点对点：也叫消息队列模型，A 系统的消息只能被 B 系统读取，其他任何系统不能读取 A 系统消息
- 发布/订阅模型：有一个 topic 的概念，可以有多个发布者，也可以有多个消费者

## kafka 的一些术语
- topic：主题
- producer：发布者，向 topic 发送消息的客户端程序，一般是连续不断的向一个或者多个 topic 发送消息
- consumer：消费者，向这些 topic 订阅消息的客户端程序
- Broker：kafka 的服务端，接收和处理客户端发送过来的请求，以及对消息的持久化；一个 kafka集群由多个 broker 组成，一般分布在不同的实例上。目的是为了高可用
- Replica：副本，也是 kafka 高可用的手段之一；备份机制，将相同的数据拷贝到多台机器上；副本的数量可配置；持久化或消息不丢失
  - Leader Replica（领导者副本）：对外提供服务，与客户端交互
  - Follower Replica（追随者副本）：被动地追随领导者副本，不能对外交互
  - 副本的工作机制：
    - 领导者副本：生成者向领导者副本写消息，消费者从领导者副本读消息
    - 追随者副本：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。
- Partitioning：分区（目的：伸缩性），一个有序不变的消息序列。每个主题下可以有多个分区。
- 消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
- 消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。
- 消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
- 重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance是Kafka消费者端实现高可用的重要手段。
- ![img.png](img.png)

## kafka 线上集群部署方案怎么做
![img_1.png](img_1.png)
- 操作系统
  - I/O模型的使用，kafka 底层使用了Java的selector，selector在Linux上的实现机制是epoll，而在Windows平台上的实现机制是select。因此在这一点上将Kafka部署在Linux上是有优势的，因为能够获得更高效的I/O性能。
  - 网络传输：在Linux部署Kafka能够享受到零拷贝技术所带来的快速数据传输特性。
  - 社区支持
- 磁盘：
  - 新增消息数
  - 消息留存时间
  - 平均消息大小
  - 备份数
  - 是否启用压缩
- 带宽

## 集群参数怎么配置
- broker端：
  - log.dirs 

## 生产者消息分区机制
- 为什么要分区
  - 负载均衡
  - 实现高伸缩性
  - 可以保证消息的有序
  - 高吞吐量
- 分区策略
  - 轮询-》即顺序分配：轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。
  - 随机：
  - 按消息键保序策略：相同的 key 会被分配到同一个分区，每个分区下的消息处理都是有顺序的
  - 地理位置的分区策略

## 生产者压缩算法
它秉承了用时间去换空间的经典trade-off思想，具体来说就是用CPU时间去换磁盘空间或网络I/O传输量，希望以较小的CPU开销带来更少的磁盘占用或更少的网络I/O传输
- 怎么压缩
  - v1 版本把多条消息压缩之后，保存到外层消息的消息体字段中
  - V2，对整个消息集合压缩，更节省磁盘空间
- 何时压缩
  - 生产端
    - compression.type
  - broker 端：两种情况下才会在 broker 端压缩
    - 与生产端用了不一样的压缩算法，先解压缩再按 broker 的压缩算法压缩，可能出现 broker 端 cpu 使用率飙升
    - broker 端消息格式发生了转换；主要是为了兼容新老版本的消费者程序
- 何时解压缩
  - consumer 解压缩
  - 怎么知道这些消息是用了哪种算法？
    - kafka 会将用了哪种压缩算法封装在消息集合中
- 各种压缩算法的对比
  - 在吞吐量方面：LZ4 > Snappy > zstd和GZIP；
  - 而在压缩比方面，zstd > LZ4 > GZIP > Snappy。
- 最佳实践
  - cpu 资源充足
  - 带宽资源充足

## 无消息丢失配置
- 什么情况下保证消息不丢失
  - Kafka只对“已提交”的消息（committed message）做有限度的持久化保证。
  - 已提交：若干个 broker 成功的接收并写入日志后，会告诉生产者程序消息已经提交成功
  - 有限度的持久化保证 ：不丢失消息是有前提的，比如n 个 broker 中，至少有一个存活
- 消息丢失的情况
  - producer 端消息没有发送成功
    - 可能是网络波动，消息没有到 broker
    - 可能是消息不合格，超出了 broker 最大承受的能力
    - 可能 broker 已经宕机了
    - 解决办法：使用带回调的发送方式
  - consumer 端位移出现了问题（offset）
    - 先更新了 offset，在消费的消息
      - 解决办法：先消费消息，再更新 offset；可能出现重复消费的问题
    - 可能自动提交了位移，但是并没有消费消息
      - 手动提交
- 最佳实践
  - 使用带回调的发送消息方式
  - 设置 acks = all，需要所有副本 broker 收到消息才算 "已提交"
  - 设置一个较大的重试次数 retries
  - 设置自动定期选举 leader 副本 = false，如果一个Broker落后原先的Leader太多，那么它一旦成为新的Leader，必然会造成消息的丢失
  - 设置replication.factor >= 3，消息多保存几份
  - 设置min.insync.replicas > 1。这依然是Broker端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”
  - 确保replication.factor > min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成replication.factor = min.insync.replicas + 1。
  - 确保消息消费完成再提交

## 拦截器
- 什么是拦截器
  - 其基本思想就是允许应用程序在不修改逻辑的情况下，动态地实现一组可插拔的事件处理逻辑链
- 分类；两者都支持链的方式，将一组拦截器串成一个大的拦截器
  - 生产者拦截器
    - 允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑
  - 消费者拦截器
    - 支持在消费消息前以及提交位移后编写特定逻辑
- 使用场景
  - 客户端监控
  - 端到端系统性能检测
  - 消息审计等功能

## 生产者如何管理 tcp 连接
- 为什么使用 tcp 连接
  - tcp 多路复用
  - 可同时轮询多个连接
- 何时建立 tcp 连接
  - 在创建KafkaProducer实例时，生产者应用会在后台创建并启动一个名为Sender的线程，该Sender线程开始运行时首先会创建与Broker的连接
  - 连接的是 bootstrap.servers 指定的所有 broker，不需要设定太多 broker，只要与一台 broker 建立连接就能拿到集群信息
  - TCP连接还可能在两个地方被创建：
    - 一个是在更新元数据后
      - 如果发现与某些Broker当前没有连接，那么它就会创建一个TCP连接
      - 更新元数据的场景
        - 尝试给不存在的 topic 发送消息
        - 设置了 metadata.max.age.ms 参数定时更新元数据
    - 另一个是在消息发送时
      - 当要发送消息时，Producer发现尚不存在与目标Broker的连接，也会创建一个
- 何时关闭连接
  - 用户主动关闭
    - producer.close() 关闭
    - 或者 kill -9 强制关闭
  - kafka 自动关闭
    - connections.max.idle.ms 默认是 9分钟（规定时间内没有“流 ”产生），可以设置 connections.max.idle.ms=-1 禁止

## Kafka消息交付可靠性保障
- 消息交互的可靠性保证
  - 最多一次：消息可能会丢失，但绝不会被重复发送
  - 至少一次（默认）：消息不会丢失，但有可能被重复发送
  - 精确一次：消息不会丢失，不会被重复发送
    - 幂等性
      - 指的是某些操作或函数能够被执行多次，但每次得到的结果都是不变的
      - Producer 幂等，props.put(“enable.idempotence”, ture)，或props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)。在 broker 端多保存一些字段，匹配到相同信息自动丢弃
        - 只能保证单分区的幂等性，同一个 topic 下的同一分区
        - 只能保证单次会话幂等，不能保证跨会话幂等，当你重启了Producer进程之后，这种幂等性保证就丧失了
    - 事务：原子性（Atomicity）、一致性(Consistency)、隔离性(Isolation)和持久性(Durability)。
      - kafka的事务机制可以保证多条消息原子性地写入到目标分区，同时也能保证Consumer只能看到事务成功提交的消息。
      - 事务型 producer
        - 事务型Producer能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败
        - 不惧怕producer进程重启
        - 如何设置
          - 和幂等性Producer一样，开启enable.idempotence = true。
          - 设置Producer端参数transactional.id。最好为其设置一个有意义的名字。
          
## 消费组
