## kafka 什么
分布式的消息引擎 或者 消息队列 - 消息中间件 也是分布式流处理平台

## kafka 的消息传输协议是怎样的
- 点对点：也叫消息队列模型，A 系统的消息只能被 B 系统读取，其他任何系统不能读取 A 系统消息
- 发布/订阅模型：有一个 topic 的概念，可以有多个发布者，也可以有多个消费者

## kafka 的一些术语
- topic：主题
- producer：发布者，向 topic 发送消息的客户端程序，一般是连续不断的向一个或者多个 topic 发送消息
- consumer：消费者，向这些 topic 订阅消息的客户端程序
- Broker：kafka 的服务端，接收和处理客户端发送过来的请求，以及对消息的持久化；一个 kafka集群由多个 broker 组成，一般分布在不同的实例上。目的是为了高可用
- Replica：副本，也是 kafka 高可用的手段之一；备份机制，将相同的数据拷贝到多台机器上；副本的数量可配置；持久化或消息不丢失
  - Leader Replica（领导者副本）：对外提供服务，与客户端交互
  - Follower Replica（追随者副本）：被动地追随领导者副本，不能对外交互
  - 副本的工作机制：
    - 领导者副本：生成者向领导者副本写消息，消费者从领导者副本读消息
    - 追随者副本：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。
- Partitioning：分区（目的：伸缩性），一个有序不变的消息序列。每个主题下可以有多个分区。
- 消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
- 消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。
- 消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
- 重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance是Kafka消费者端实现高可用的重要手段。
- ![img.png](img.png)

## kafka 线上集群部署方案怎么做
![img_1.png](img_1.png)
- 操作系统
  - I/O模型的使用，kafka 底层使用了Java的selector，selector在Linux上的实现机制是epoll，而在Windows平台上的实现机制是select。因此在这一点上将Kafka部署在Linux上是有优势的，因为能够获得更高效的I/O性能。
  - 网络传输：在Linux部署Kafka能够享受到零拷贝技术所带来的快速数据传输特性。
  - 社区支持
- 磁盘：
  - 新增消息数
  - 消息留存时间
  - 平均消息大小
  - 备份数
  - 是否启用压缩
- 带宽

## 生产者压缩消息
- 怎么压缩
  - v1 版本把多条消息压缩之后，保存到外层消息的消息体字段中
  - V2，对整个消息集合压缩，更节省磁盘空间
- 何时压缩
  - 生产端
    - compression.type
  - broker 端：两种情况下才会在 broker 端压缩
    - 与生产端用了不一样的压缩算法，先解压缩再按 broker 的压缩算法压缩，可能出现 broker 端 cpu 使用率飙升
    - broker 端消息格式发生了转换；主要是为了兼容新老版本的消费者程序
- 何时解压缩
  - consumer 解压缩
  - 怎么知道这些消息是用了哪种算法？
    - kafka 会将用了哪种压缩算法封装在消息集合中
- 各种压缩算法的对比
  - 在吞吐量方面：LZ4 > Snappy > zstd和GZIP；
  - 而在压缩比方面，zstd > LZ4 > GZIP > Snappy。
- 最佳实践
  - cpu 资源充足
  - 带宽资源充足

## 无消息丢失配置
- 什么情况下保证消息不丢失
  - Kafka只对“已提交”的消息（committed message）做有限度的持久化保证。
  - 已提交：若干个 broker 成功的接收并写入日志后，会告诉生产者程序消息已经提交成功
  - 有限度的持久化保证 ：不丢失消息是有前提的，比如n 个 broker 中，至少有一个存活
- 消息丢失的情况
  - producer 端消息没有发送成功
    - 可能是网络波动，消息没有到 broker
    - 可能是消息不合格，超出了 broker 最大承受的能力
    - 可能 broker 已经宕机了
    - 解决办法：使用带回调的发送方式
  - consumer 端位移出现了问题（offset）
    - 先更新了 offset，在消费的消息
      - 解决办法：先消费消息，再更新 offset；可能出现重复消费的问题
    - 可能自动提交了位移，但是并没有消费消息
      - 手动提交
- 最佳实践
  - 使用带回调的发送消息方式
  - 设置 acks = all，需要所有副本 broker 收到消息才算 "已提交"
  - 设置一个较大的重试次数 retries
  - 设置自动定期选举 leader 副本 = false，如果一个Broker落后原先的Leader太多，那么它一旦成为新的Leader，必然会造成消息的丢失
  - 设置replication.factor >= 3，消息多保存几份
  - 设置min.insync.replicas > 1。这依然是Broker端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”
  - 确保replication.factor > min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成replication.factor = min.insync.replicas + 1。
  - 确保消息消费完成再提交

## 拦截器
